{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:48.504449Z",
     "iopub.status.busy": "2022-08-27T15:38:48.503970Z",
     "iopub.status.idle": "2022-08-27T15:38:48.526383Z",
     "shell.execute_reply": "2022-08-27T15:38:48.525449Z",
     "shell.execute_reply.started": "2022-08-27T15:38:48.504344Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -q ../input/pydicom-utilities/pydicom_utilities/pylibjpeg-1.4.0-py3-none-any.whl\n",
    "#!pip install -q ../input/pydicom-utilities/pydicom_utilities/python_gdcm-3.0.14-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:48.528909Z",
     "iopub.status.busy": "2022-08-27T15:38:48.528253Z",
     "iopub.status.idle": "2022-08-27T15:38:57.550173Z",
     "shell.execute_reply": "2022-08-27T15:38:57.548996Z",
     "shell.execute_reply.started": "2022-08-27T15:38:48.528872Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "import time\n",
    "\n",
    "import pydicom\n",
    "import pathlib\n",
    "import glob \n",
    "from tqdm import tqdm \n",
    "import cv2 as cv\n",
    "\n",
    "#for x in (os.listdir('/kaggle/working/')):\n",
    "#    shutil.rmtree(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:57.552293Z",
     "iopub.status.busy": "2022-08-27T15:38:57.551646Z",
     "iopub.status.idle": "2022-08-27T15:38:57.559135Z",
     "shell.execute_reply": "2022-08-27T15:38:57.557961Z",
     "shell.execute_reply.started": "2022-08-27T15:38:57.552258Z"
    }
   },
   "outputs": [],
   "source": [
    "## Parameters\n",
    "sns.set()\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "#IMAGE_SIZE = (512, 512)\n",
    "IMG_SIZE = (100,100)\n",
    "SEED = 42\n",
    "\n",
    "# set seed\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:57.562219Z",
     "iopub.status.busy": "2022-08-27T15:38:57.561035Z",
     "iopub.status.idle": "2022-08-27T15:38:57.578884Z",
     "shell.execute_reply": "2022-08-27T15:38:57.577994Z",
     "shell.execute_reply.started": "2022-08-27T15:38:57.562162Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    img=pydicom.dcmread(path)\n",
    "    data=img.pixel_array\n",
    "    data=data-np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data=data/np.max(data)\n",
    "    data=(data*255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:57.581752Z",
     "iopub.status.busy": "2022-08-27T15:38:57.581413Z",
     "iopub.status.idle": "2022-08-27T15:38:57.589793Z",
     "shell.execute_reply": "2022-08-27T15:38:57.588849Z",
     "shell.execute_reply.started": "2022-08-27T15:38:57.581713Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "    \"\"\"\n",
    "    a function that will load the dataset from a list of image paths\n",
    "    \"\"\"\n",
    "    for path in img_list:\n",
    "        data = load_dicom(path)\n",
    "        yield data  # return the data has generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:57.593566Z",
     "iopub.status.busy": "2022-08-27T15:38:57.592839Z",
     "iopub.status.idle": "2022-08-27T15:38:57.723536Z",
     "shell.execute_reply": "2022-08-27T15:38:57.722472Z",
     "shell.execute_reply.started": "2022-08-27T15:38:57.593533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1.2.826.0.1.3680043.17625',\n",
       " '1.2.826.0.1.3680043.3850',\n",
       " '1.2.826.0.1.3680043.2286']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR='../input/rsna-2022-cervical-spine-fracture-detection/'\n",
    "\n",
    "train_images_dir=DIR+'train_images/'  \n",
    "test_images_dir=DIR+'test_images/'  \n",
    "segmentations_dir=DIR+'segmentations/'  \n",
    "\n",
    "train_images_list=os.listdir(train_images_dir)\n",
    "test_images_list=os.listdir(test_images_dir)\n",
    "segmentations_list=os.listdir(segmentations_dir)\n",
    "\n",
    "print(len(train_images_list))\n",
    "train_images_list[0:3]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:57.725701Z",
     "iopub.status.busy": "2022-08-27T15:38:57.725043Z",
     "iopub.status.idle": "2022-08-27T15:38:57.816489Z",
     "shell.execute_reply": "2022-08-27T15:38:57.815226Z",
     "shell.execute_reply.started": "2022-08-27T15:38:57.725668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2019 entries, 0 to 2018\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   StudyInstanceUID  2019 non-null   object\n",
      " 1   patient_overall   2019 non-null   int64 \n",
      " 2   C1                2019 non-null   int64 \n",
      " 3   C2                2019 non-null   int64 \n",
      " 4   C3                2019 non-null   int64 \n",
      " 5   C4                2019 non-null   int64 \n",
      " 6   C5                2019 non-null   int64 \n",
      " 7   C6                2019 non-null   int64 \n",
      " 8   C7                2019 non-null   int64 \n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 142.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.21561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.12351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.1363</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1.2.826.0.1.3680043.21684</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1.2.826.0.1.3680043.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1.2.826.0.1.3680043.14341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1.2.826.0.1.3680043.12053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2019 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7\n",
       "0      1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0\n",
       "1     1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0\n",
       "2     1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n",
       "3     1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0\n",
       "4      1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0\n",
       "...                         ...              ...  ..  ..  ..  ..  ..  ..  ..\n",
       "2014  1.2.826.0.1.3680043.21684                1   0   1   0   0   0   1   1\n",
       "2015   1.2.826.0.1.3680043.4786                1   0   0   0   0   0   0   1\n",
       "2016  1.2.826.0.1.3680043.14341                0   0   0   0   0   0   0   0\n",
       "2017  1.2.826.0.1.3680043.12053                0   0   0   0   0   0   0   0\n",
       "2018  1.2.826.0.1.3680043.18786                1   0   0   0   0   0   0   1\n",
       "\n",
       "[2019 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_bounding_boxes_csv=pd.read_csv(DIR+'train_bounding_boxes.csv')\n",
    "sample_submission_csv=pd.read_csv(DIR+'sample_submission.csv')\n",
    "test_csv=pd.read_csv(DIR+'test.csv')\n",
    "\n",
    "train_csv=pd.read_csv(DIR+'train.csv')\n",
    "\n",
    "display(train_csv.info())\n",
    "display(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:57.818804Z",
     "iopub.status.busy": "2022-08-27T15:38:57.818139Z",
     "iopub.status.idle": "2022-08-27T15:38:57.839071Z",
     "shell.execute_reply": "2022-08-27T15:38:57.838322Z",
     "shell.execute_reply.started": "2022-08-27T15:38:57.818766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  ,  (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>fractured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10197_C1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10454_C1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10690_C1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id  fractured\n",
       "0  1.2.826.0.1.3680043.10197_C1        0.5\n",
       "1  1.2.826.0.1.3680043.10454_C1        0.5\n",
       "2  1.2.826.0.1.3680043.10690_C1        0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test.csv  ,  (3, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>prediction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10197_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.10197</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10454_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.10454</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10690_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.10690</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id           StudyInstanceUID prediction_type\n",
       "0  1.2.826.0.1.3680043.10197_C1  1.2.826.0.1.3680043.10197              C1\n",
       "1  1.2.826.0.1.3680043.10454_C1  1.2.826.0.1.3680043.10454              C1\n",
       "2  1.2.826.0.1.3680043.10690_C1  1.2.826.0.1.3680043.10690              C1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sample_submission.csv  , ',sample_submission_csv.shape)\n",
    "display(sample_submission_csv)\n",
    "print('')\n",
    "print('test.csv  , ', test_csv.shape)\n",
    "test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:57.840360Z",
     "iopub.status.busy": "2022-08-27T15:38:57.840001Z",
     "iopub.status.idle": "2022-08-27T15:38:58.276405Z",
     "shell.execute_reply": "2022-08-27T15:38:58.275073Z",
     "shell.execute_reply.started": "2022-08-27T15:38:57.840327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Jum_dmc</th>\n",
       "      <th>TransferSyntaxUID</th>\n",
       "      <th>PhotometricInterpretation</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>RowsColumns</th>\n",
       "      <th>PixelSpacing</th>\n",
       "      <th>WindowCenter</th>\n",
       "      <th>WindowWidth</th>\n",
       "      <th>PixelRepresentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>22327</td>\n",
       "      <td>458</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.384766, 0.384766]</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>25399</td>\n",
       "      <td>458</td>\n",
       "      <td>JPEG Lossless, Non-Hierarchical, First-Order P...</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>12</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.361328125, 0.361328125]</td>\n",
       "      <td>[410, 50]</td>\n",
       "      <td>[3665, 350]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>5876</td>\n",
       "      <td>458</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.320, 0.320]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID PatientID  Jum_dmc  \\\n",
       "0  1.2.826.0.1.3680043.22327     22327      458   \n",
       "1  1.2.826.0.1.3680043.25399     25399      458   \n",
       "2   1.2.826.0.1.3680043.5876      5876      458   \n",
       "\n",
       "                                   TransferSyntaxUID  \\\n",
       "0                          Explicit VR Little Endian   \n",
       "1  JPEG Lossless, Non-Hierarchical, First-Order P...   \n",
       "2                          Explicit VR Little Endian   \n",
       "\n",
       "  PhotometricInterpretation  BitsStored RowsColumns  \\\n",
       "0               MONOCHROME2          16     512x512   \n",
       "1               MONOCHROME2          12     512x512   \n",
       "2               MONOCHROME2          16     512x512   \n",
       "\n",
       "                 PixelSpacing WindowCenter  WindowWidth  PixelRepresentation  \n",
       "0        [0.384766, 0.384766]        550.0       2000.0                    1  \n",
       "1  [0.361328125, 0.361328125]    [410, 50]  [3665, 350]                    0  \n",
       "2              [0.320, 0.320]        500.0       2500.0                    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_dir=DIR + f\"test_images\"\n",
    "\n",
    "#os.listdir(test_images_dir)\n",
    "test_df=pd.DataFrame({'StudyInstanceUID':os.listdir(test_images_dir)})\n",
    "test_df\n",
    "\n",
    "Jum_dmc=[]\n",
    "PatientID=[]\n",
    "InstanceNumber=[]\n",
    "BS=[]\n",
    "TransferSyntaxUID=[]\n",
    "PhotometricInterpretation=[]\n",
    "RowsColumns=[]\n",
    "PixelSpacing=[]\n",
    "WindowCenter=[]\n",
    "WindowWidth=[]\n",
    "PixelRepresentation=[]\n",
    "\n",
    "for pan in range (len(test_df)):\n",
    "    w=test_df.loc[pan]['StudyInstanceUID']\n",
    "    pat = DIR+'test_images/'+w \n",
    "    z=os.listdir(pat)[0]\n",
    "    \n",
    "    Jum_dmc.append(len(os.listdir(pat)))\n",
    "    PatientID.append(pydicom.read_file(pat+'/'+z).PatientID)\n",
    "    #InstanceNumber.append(pydicom.read_file(pat+'/'+z).InstanceNumber)\n",
    "    BS.append(pydicom.read_file(pat+'/'+z).BitsStored)\n",
    "    TransferSyntaxUID.append(pydicom.read_file(pat+'/'+z).file_meta.TransferSyntaxUID.name)\n",
    "    PhotometricInterpretation.append(pydicom.read_file(pat+'/'+z).PhotometricInterpretation)\n",
    "    RowsColumns.append(str(pydicom.read_file(pat+'/'+z).Rows)+'x'+str(pydicom.read_file(pat+'/'+z).Columns))\n",
    "    PixelSpacing.append(pydicom.read_file(pat+'/'+z).PixelSpacing)\n",
    "    WindowCenter.append(pydicom.read_file(pat+'/'+z).WindowCenter)\n",
    "    WindowWidth.append(pydicom.read_file(pat+'/'+z).WindowWidth)\n",
    "    PixelRepresentation.append(pydicom.read_file(pat+'/'+z).PixelRepresentation)\n",
    "    \n",
    "test_df['PatientID']=PatientID\n",
    "#test_df['InstanceNumber']=InstanceNumber\n",
    "test_df['Jum_dmc']=len(os.listdir(pat))\n",
    "test_df['TransferSyntaxUID']=TransferSyntaxUID\n",
    "test_df['PhotometricInterpretation']=PhotometricInterpretation\n",
    "test_df['BitsStored']=BS\n",
    "test_df['RowsColumns']=RowsColumns\n",
    "test_df['PixelSpacing']=PixelSpacing\n",
    "test_df['WindowCenter']=WindowCenter\n",
    "test_df['WindowWidth']=WindowWidth\n",
    "test_df['PixelRepresentation']=PixelRepresentation\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:38:58.278339Z",
     "iopub.status.busy": "2022-08-27T15:38:58.277891Z",
     "iopub.status.idle": "2022-08-27T15:42:20.853441Z",
     "shell.execute_reply": "2022-08-27T15:42:20.852371Z",
     "shell.execute_reply.started": "2022-08-27T15:38:58.278305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah_dcm/pasien , min: 69  , max: 825  , Total data dcm: 161442\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>Jum_dcm</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>TransferSyntaxUID</th>\n",
       "      <th>PhotometricInterpretation</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>RowsColumns</th>\n",
       "      <th>PixelSpacing</th>\n",
       "      <th>WindowCenter</th>\n",
       "      <th>WindowWidth</th>\n",
       "      <th>PixelRepresentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>645</td>\n",
       "      <td>10016</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.275391, 0.275391]</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>10051</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.253906, 0.253906]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.10204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>10204</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.416016, 0.416016]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.10261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>10261</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.544921994209, 0.544921994209]</td>\n",
       "      <td>752.0</td>\n",
       "      <td>2706.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.10400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>10400</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.332031, 0.332031]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1.2.826.0.1.3680043.9796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>9796</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.302734, 0.302734]</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1.2.826.0.1.3680043.9886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "      <td>9886</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.332031, 0.332031]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1.2.826.0.1.3680043.9904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>9904</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.292969, 0.292969]</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1.2.826.0.1.3680043.9940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>9940</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.234375, 0.234375]</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>1.2.826.0.1.3680043.9996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>9996</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.326172, 0.326172]</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7  \\\n",
       "0    1.2.826.0.1.3680043.10016                1   0   1   0   0   0   0   0   \n",
       "1    1.2.826.0.1.3680043.10051                1   0   0   0   1   0   0   0   \n",
       "2    1.2.826.0.1.3680043.10204                1   1   1   0   0   0   0   0   \n",
       "3    1.2.826.0.1.3680043.10261                1   1   1   0   0   0   0   0   \n",
       "4    1.2.826.0.1.3680043.10400                1   0   0   0   1   1   0   0   \n",
       "..                         ...              ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "437   1.2.826.0.1.3680043.9796                1   0   0   0   0   0   1   1   \n",
       "438   1.2.826.0.1.3680043.9886                1   1   0   0   0   0   0   0   \n",
       "439   1.2.826.0.1.3680043.9904                1   0   0   0   0   1   0   0   \n",
       "440   1.2.826.0.1.3680043.9940                1   0   0   0   1   1   0   0   \n",
       "441   1.2.826.0.1.3680043.9996                1   0   1   0   0   0   0   0   \n",
       "\n",
       "     Jum_dcm PatientID          TransferSyntaxUID PhotometricInterpretation  \\\n",
       "0        645     10016  Explicit VR Little Endian               MONOCHROME2   \n",
       "1        272     10051  Explicit VR Little Endian               MONOCHROME2   \n",
       "2        331     10204  Explicit VR Little Endian               MONOCHROME2   \n",
       "3        308     10261  Explicit VR Little Endian               MONOCHROME2   \n",
       "4        270     10400  Explicit VR Little Endian               MONOCHROME2   \n",
       "..       ...       ...                        ...                       ...   \n",
       "437      310      9796  Explicit VR Little Endian               MONOCHROME2   \n",
       "438      329      9886  Explicit VR Little Endian               MONOCHROME2   \n",
       "439      275      9904  Explicit VR Little Endian               MONOCHROME2   \n",
       "440      259      9940  Explicit VR Little Endian               MONOCHROME2   \n",
       "441      296      9996  Explicit VR Little Endian               MONOCHROME2   \n",
       "\n",
       "     BitsStored RowsColumns                      PixelSpacing WindowCenter  \\\n",
       "0            16     512x512              [0.275391, 0.275391]        300.0   \n",
       "1            16     512x512              [0.253906, 0.253906]        400.0   \n",
       "2            16     512x512              [0.416016, 0.416016]        500.0   \n",
       "3            16     512x512  [0.544921994209, 0.544921994209]        752.0   \n",
       "4            16     512x512              [0.332031, 0.332031]        500.0   \n",
       "..          ...         ...                               ...          ...   \n",
       "437          16     512x512              [0.302734, 0.302734]        250.0   \n",
       "438          16     512x512              [0.332031, 0.332031]        500.0   \n",
       "439          16     512x512              [0.292969, 0.292969]        550.0   \n",
       "440          16     512x512              [0.234375, 0.234375]        550.0   \n",
       "441          16     512x512              [0.326172, 0.326172]        250.0   \n",
       "\n",
       "    WindowWidth  PixelRepresentation  \n",
       "0        2000.0                    1  \n",
       "1        2500.0                    1  \n",
       "2        2000.0                    1  \n",
       "3        2706.0                    1  \n",
       "4        2000.0                    1  \n",
       "..          ...                  ...  \n",
       "437      2500.0                    1  \n",
       "438      2000.0                    1  \n",
       "439      2000.0                    1  \n",
       "440      2000.0                    1  \n",
       "441      2500.0                    1  \n",
       "\n",
       "[442 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t\t       \u001b[91mTotal data dcm :    161442\u001b[0m\n",
      "\n",
      "img_count: 161442\n",
      "\n",
      "C1=1: 71 dari 442\n",
      "C1=0: 371 dari 442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_csv_=pd.read_csv(DIR+'train.csv')\n",
    "lim1=0   #0    #350  #300    #250    #0    220\n",
    "lim2=1000000  #250  #400  #350    #300    #220  250\n",
    "\n",
    "\n",
    "Jum_dcm=[]\n",
    "PatientID=[]\n",
    "InstanceNumber=[]\n",
    "BS=[]\n",
    "TransferSyntaxUID=[]\n",
    "PhotometricInterpretation=[]\n",
    "RowsColumns=[]\n",
    "PixelSpacing=[]\n",
    "WindowCenter=[]\n",
    "WindowWidth=[]\n",
    "PixelRepresentation=[]\n",
    "\n",
    "for pan in range (len(train_csv_)):\n",
    "    w=train_csv_.loc[pan]['StudyInstanceUID']\n",
    "    \n",
    "    pat = DIR+'train_images/'+w \n",
    "    z=os.listdir(pat)[0]\n",
    "\n",
    "    Jum_dcm.append(len(os.listdir(pat)))\n",
    "    \n",
    "    PatientID.append(pydicom.read_file(pat+'/'+z).PatientID)\n",
    "    TransferSyntaxUID.append(pydicom.read_file(pat+'/'+z).file_meta.TransferSyntaxUID.name)\n",
    "    PhotometricInterpretation.append(pydicom.read_file(pat+'/'+z).PhotometricInterpretation)\n",
    "    BS.append(pydicom.read_file(pat+'/'+z).BitsStored)\n",
    "    RowsColumns.append(str(pydicom.read_file(pat+'/'+z).Rows)+'x'+str(pydicom.read_file(pat+'/'+z).Columns))\n",
    "    PixelSpacing.append(pydicom.read_file(pat+'/'+z).PixelSpacing)\n",
    "    WindowCenter.append(pydicom.read_file(pat+'/'+z).WindowCenter)\n",
    "    WindowWidth.append(pydicom.read_file(pat+'/'+z).WindowWidth)\n",
    "    PixelRepresentation.append(pydicom.read_file(pat+'/'+z).PixelRepresentation)\n",
    "    \n",
    "train_csv_['Jum_dcm']=Jum_dcm\n",
    "\n",
    "# INSERT:\n",
    "train_csv_['PatientID']=PatientID\n",
    "\n",
    "train_csv_['TransferSyntaxUID']=TransferSyntaxUID\n",
    "train_csv_['PhotometricInterpretation']=PhotometricInterpretation\n",
    "train_csv_['BitsStored']=BS\n",
    "train_csv_['RowsColumns']=RowsColumns\n",
    "train_csv_['PixelSpacing']=PixelSpacing\n",
    "train_csv_['WindowCenter']=WindowCenter\n",
    "train_csv_['WindowWidth']=WindowWidth\n",
    "train_csv_['PixelRepresentation']=PixelRepresentation\n",
    "\n",
    "# SYARAT-SYARAT:\n",
    "train_csv_=train_csv_.loc[train_csv_.Jum_dcm>lim1].loc[train_csv_.Jum_dcm<lim2]\n",
    "train_csv_=train_csv_.loc[train_csv_.patient_overall==1]\n",
    "train_csv_=train_csv_.loc[train_csv_.RowsColumns=='512x512']\n",
    "train_csv_=train_csv_.loc[train_csv_.TransferSyntaxUID!='Implicit VR Little Endian']\n",
    "train_csv_=train_csv_.loc[train_csv_.PhotometricInterpretation=='MONOCHROME2']\n",
    "train_csv_=train_csv_.loc[train_csv_.TransferSyntaxUID!='JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])']\n",
    "train_csv_=train_csv_.loc[train_csv_.BitsStored==16]\n",
    "train_csv_=train_csv_.loc[train_csv_.PixelRepresentation==1]\n",
    "\n",
    "\n",
    "#print('Kisaran Jum_dcm :',lim1,'-',lim2)\n",
    "print('Jumlah_dcm/pasien , min:',train_csv_.Jum_dcm.min(), ' , max:',train_csv_.Jum_dcm.max(), ' , Total data dcm:',train_csv_.Jum_dcm.sum())\n",
    "print('')\n",
    "\n",
    "train_csv_=train_csv_.sort_values(by=['StudyInstanceUID'],ignore_index=True)\n",
    "display(train_csv_) #.head())\n",
    "\n",
    "img_co=train_csv_.Jum_dcm.sum()\n",
    "print('\\t\\t\\t\\t\\t\\t      ','\\033[91m'+'Total data dcm :    ' +str(img_co) + '\\033[0m')\n",
    "print('')\n",
    "print('img_count:',img_co)\n",
    "print('')\n",
    "print('C1=1:',train_csv_.loc[train_csv_.C1==1]['C1'].count(),'dari',train_csv_.C1.count())\n",
    "print('C1=0:',train_csv_.loc[train_csv_.C1==0]['C1'].count(),'dari',train_csv_.C1.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:42:20.855474Z",
     "iopub.status.busy": "2022-08-27T15:42:20.855111Z",
     "iopub.status.idle": "2022-08-27T15:42:20.929955Z",
     "shell.execute_reply": "2022-08-27T15:42:20.928109Z",
     "shell.execute_reply.started": "2022-08-27T15:42:20.855444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kisaran Jum_dcm : 0 - 1000000\n",
      "Jumlah_dcm/pasien , min: 69  , max: 681  , Total data dcm: 28902\n",
      "img_count: 28902\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>Jum_dcm</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>TransferSyntaxUID</th>\n",
       "      <th>PhotometricInterpretation</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>RowsColumns</th>\n",
       "      <th>PixelSpacing</th>\n",
       "      <th>WindowCenter</th>\n",
       "      <th>WindowWidth</th>\n",
       "      <th>PixelRepresentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.10051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>10051</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.253906, 0.253906]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.10815</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>10815</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.265625, 0.265625]</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.11227</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>11227</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.341797, 0.341797]</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.12328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>12328</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.281250, 0.281250]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.12533</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>278</td>\n",
       "      <td>12533</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.292969, 0.292969]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.2.826.0.1.3680043.8198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8198</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.271484, 0.271484]</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.2.826.0.1.3680043.8511</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>8511</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.462891, 0.462891]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.2.826.0.1.3680043.8519</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>8519</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.248047, 0.248047]</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.2.826.0.1.3680043.8693</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>8693</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.488281, 0.488281]</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.2.826.0.1.3680043.9940</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>9940</td>\n",
       "      <td>Explicit VR Little Endian</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>16</td>\n",
       "      <td>512x512</td>\n",
       "      <td>[0.234375, 0.234375]</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7  \\\n",
       "0   1.2.826.0.1.3680043.10051                1   0   0   0   1   0   0   0   \n",
       "1   1.2.826.0.1.3680043.10815                1   0   0   0   1   1   1   0   \n",
       "2   1.2.826.0.1.3680043.11227                1   1   0   0   0   0   0   0   \n",
       "3   1.2.826.0.1.3680043.12328                1   0   0   0   0   0   1   0   \n",
       "4   1.2.826.0.1.3680043.12533                1   0   1   0   0   0   0   1   \n",
       "..                        ...              ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "80   1.2.826.0.1.3680043.8198                1   1   0   0   0   0   0   0   \n",
       "81   1.2.826.0.1.3680043.8511                1   0   0   0   0   0   1   0   \n",
       "82   1.2.826.0.1.3680043.8519                1   1   0   0   0   0   0   0   \n",
       "83   1.2.826.0.1.3680043.8693                1   0   0   0   0   0   1   0   \n",
       "84   1.2.826.0.1.3680043.9940                1   0   0   0   1   1   0   0   \n",
       "\n",
       "    Jum_dcm PatientID          TransferSyntaxUID PhotometricInterpretation  \\\n",
       "0       272     10051  Explicit VR Little Endian               MONOCHROME2   \n",
       "1       242     10815  Explicit VR Little Endian               MONOCHROME2   \n",
       "2       294     11227  Explicit VR Little Endian               MONOCHROME2   \n",
       "3       273     12328  Explicit VR Little Endian               MONOCHROME2   \n",
       "4       278     12533  Explicit VR Little Endian               MONOCHROME2   \n",
       "..      ...       ...                        ...                       ...   \n",
       "80      232      8198  Explicit VR Little Endian               MONOCHROME2   \n",
       "81      384      8511  Explicit VR Little Endian               MONOCHROME2   \n",
       "82      249      8519  Explicit VR Little Endian               MONOCHROME2   \n",
       "83       69      8693  Explicit VR Little Endian               MONOCHROME2   \n",
       "84      259      9940  Explicit VR Little Endian               MONOCHROME2   \n",
       "\n",
       "    BitsStored RowsColumns          PixelSpacing WindowCenter WindowWidth  \\\n",
       "0           16     512x512  [0.253906, 0.253906]        400.0      2500.0   \n",
       "1           16     512x512  [0.265625, 0.265625]        350.0      2000.0   \n",
       "2           16     512x512  [0.341797, 0.341797]        250.0      2500.0   \n",
       "3           16     512x512  [0.281250, 0.281250]        400.0      2500.0   \n",
       "4           16     512x512  [0.292969, 0.292969]        400.0      2500.0   \n",
       "..         ...         ...                   ...          ...         ...   \n",
       "80          16     512x512  [0.271484, 0.271484]        400.0      2500.0   \n",
       "81          16     512x512  [0.462891, 0.462891]        500.0      2000.0   \n",
       "82          16     512x512  [0.248047, 0.248047]        550.0      2000.0   \n",
       "83          16     512x512  [0.488281, 0.488281]        350.0      2000.0   \n",
       "84          16     512x512  [0.234375, 0.234375]        550.0      2000.0   \n",
       "\n",
       "    PixelRepresentation  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "..                  ...  \n",
       "80                    1  \n",
       "81                    1  \n",
       "82                    1  \n",
       "83                    1  \n",
       "84                    1  \n",
       "\n",
       "[85 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t      \u001b[91mTotal data dcm :    28902\u001b[0m\n",
      "\n",
      "img_count: 28902\n",
      "\n",
      "C1=1: 18 dari 85\n",
      "C1=0: 67 dari 85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tbb=pd.DataFrame({'StudyInstanceUID':train_bounding_boxes_csv.StudyInstanceUID.unique()})\n",
    "#train_csv_=pd.read_csv(DATA_DIR+'train.csv').copy()\n",
    "train_csv_tbb=train_csv_.set_index('StudyInstanceUID').join(tbb.set_index('StudyInstanceUID'), how=\"inner\").reset_index()\n",
    "\n",
    "#img_count=train_csv_tbb.Jum_dcm.sum()\n",
    "\n",
    "print('Kisaran Jum_dcm :',lim1,'-',lim2)\n",
    "print('Jumlah_dcm/pasien , min:',train_csv_tbb.Jum_dcm.min(), ' , max:',train_csv_tbb.Jum_dcm.max(), ' , Total data dcm:',train_csv_tbb.Jum_dcm.sum())\n",
    "print('img_count:',train_csv_tbb.Jum_dcm.sum())\n",
    "print('')\n",
    "\n",
    "display(train_csv_tbb)\n",
    "img_co=train_csv_tbb.Jum_dcm.sum()\n",
    "print('\\t\\t\\t\\t\\t     ','\\033[91m'+'Total data dcm :    ' +str(img_co) + '\\033[0m')\n",
    "print('')\n",
    "print('img_count:',img_co)\n",
    "print('')\n",
    "print('C1=1:',train_csv_tbb.loc[train_csv_.C1==1]['C1'].count(),'dari',train_csv_tbb.C1.count())\n",
    "print('C1=0:',train_csv_tbb.loc[train_csv_.C1==0]['C1'].count(),'dari',train_csv_tbb.C1.count())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:42:20.932744Z",
     "iopub.status.busy": "2022-08-27T15:42:20.931728Z",
     "iopub.status.idle": "2022-08-27T15:42:20.955484Z",
     "shell.execute_reply": "2022-08-27T15:42:20.953927Z",
     "shell.execute_reply.started": "2022-08-27T15:42:20.932700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 1258 28902\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jum_dcm</th>\n",
       "      <th>Group_dcm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>661</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>665</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>673</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>681</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Jum_dcm  Group_dcm\n",
       "0        69         69\n",
       "1       173        173\n",
       "2       229        229\n",
       "3       232        232\n",
       "4       238        238\n",
       "..      ...        ...\n",
       "66      649        649\n",
       "67      661        661\n",
       "68      665        665\n",
       "69      673        673\n",
       "70      681        681\n",
       "\n",
       "[71 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dcm=pd.DataFrame(train_csv_tbb.sort_values(by=['Jum_dcm'],ignore_index=True)['Jum_dcm']).copy() \n",
    "A=df_dcm.Jum_dcm.unique().tolist()   #.size\n",
    "B=df_dcm.groupby(['Jum_dcm'])['Jum_dcm'].sum().values  #.size\n",
    "C=pd.DataFrame({'Jum_dcm':A, 'Group_dcm':B})\n",
    "print(C.Group_dcm.min(), C.Group_dcm.max(),C.Group_dcm.sum())\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T15:42:20.957578Z",
     "iopub.status.busy": "2022-08-27T15:42:20.956656Z",
     "iopub.status.idle": "2022-08-27T15:42:21.313752Z",
     "shell.execute_reply": "2022-08-27T15:42:21.309233Z",
     "shell.execute_reply.started": "2022-08-27T15:42:20.957544Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17/3957423419.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.314905Z",
     "iopub.status.idle": "2022-08-27T15:42:21.315341Z",
     "shell.execute_reply": "2022-08-27T15:42:21.315163Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.315123Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#train_images_dir=DIR+'train_images/'\n",
    "#os.listdir(train_images_dir)[0:2]\n",
    "\n",
    "#covert dcm to jpg/png\n",
    "import cv2\n",
    "from PIL import Image\n",
    "IMG_SIZE=200\n",
    "\n",
    "# Specify the .dcm folder path\n",
    "\n",
    "train_JPEG_BS_=train_csv_tbb.copy()\n",
    "\n",
    "folder_path = train_JPEG_BS_.StudyInstanceUID.values.tolist()  #[0:2]\n",
    "f_dest='train_images_'+str(lim1)+'_'+str(lim2)\n",
    "\n",
    "try: \n",
    "    os.mkdir(f_dest)\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "\n",
    "i=0 \n",
    "for n, image in enumerate(folder_path[0:]):  #2018\n",
    "    #print('image:',image)\n",
    "    \n",
    "    fold=train_JPEG_BS_.loc[train_JPEG_BS_.StudyInstanceUID==str(image)].C1.values[0]\n",
    "    \n",
    "    try: \n",
    "        os.mkdir(f_dest+'/'+str(fold))\n",
    "    except OSError as error: \n",
    "        print(error)  \n",
    "        \n",
    "    for img in os.listdir(train_images_dir+image)[0:]:       \n",
    "        ds = pydicom.read_file(train_images_dir+image+'/'+img)\n",
    "        #ds=load_dicom(os.path.join(train_images_dir+image+'/'+img))\n",
    "\n",
    "        pixel_array_numpy = ds.pixel_array\n",
    "        pixel_array_numpy = cv.resize(pixel_array_numpy, (IMG_SIZE, IMG_SIZE))\n",
    "  \n",
    "        img_mem = Image.fromarray(pixel_array_numpy)\n",
    "        #print('img_mem:',img_mem)\n",
    "        #img_mem.save(f_dest+'/'+str(image)+'/'+img.replace(\".dcm\",\".png\"))\n",
    "               \n",
    "        img_mem.save(f_dest+'/'+str(fold)+'/'+str(image)+'.'+str(img).replace(\".dcm\",\".png\"))\n",
    "        #print('f_dest:',f_dest+'/'+str(fold)+'/'+str(image)+'.'+str(img).replace(\".dcm\",\".png\"))\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            #print('   ',train_images_dir+image+'/'+img)\n",
    "            print('{} image converted to png'.format(i))\n",
    "            print('   f_dest:',f_dest+'/'+str(fold)+'/'+str(image)+'.'+str(img).replace(\".dcm\",\".png\"))\n",
    "        i+=1\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"makedf\"></a>\n",
    "# <center>Read in images and create a dataframe of image paths and class labels</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.317331Z",
     "iopub.status.idle": "2022-08-27T15:42:21.318289Z",
     "shell.execute_reply": "2022-08-27T15:42:21.317964Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.317935Z"
    }
   },
   "outputs": [],
   "source": [
    "#shutil.rmtree('aug')\n",
    "\n",
    "DIR='../input/rsna-2022-cervical-spine-fracture-detection/'\n",
    "sdir=(DIR+'train_images/')\n",
    "\n",
    "min_samples=0 # set limit for minimum images a class must have to be included in the dataframe\n",
    "filepaths = []\n",
    "labels=[] \n",
    "classlist=os.listdir(sdir)[0:]   \n",
    "#for klass in classlist:\n",
    "#for klass in train_JPEG_BS_.StudyInstanceUID.tolist()[0:]:\n",
    "for klass in (os.listdir('/kaggle/working/train_images_'+str(lim1)+'_'+str(lim2))):\n",
    "    \n",
    "    classpath=os.path.join('/kaggle/working/train_images_'+str(lim1)+'_'+str(lim2), klass)\n",
    "    flist=os.listdir(classpath)\n",
    "    \n",
    "    #print('klass:',klass)\n",
    "    \n",
    "    #path_0=str(classpath)+'/'+flist[1]\n",
    "    #print('path_0:',path_0)\n",
    "    #dicom_file = pydicom.read_file(path_0)\n",
    "    #tx_meta='JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])'\n",
    "    #if dicom_file.file_meta.TransferSyntaxUID.name == tx_meta or dicom_file.BitsStored!=16:\n",
    "    #    print('Not included:',len(flist),'file dcm ,folder: ',classpath)\n",
    "    #    continue\n",
    "            \n",
    "    if len(flist) >= min_samples:\n",
    "        for f in flist:\n",
    "            #print('f:',f)\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            #print('fpath:',fpath)\n",
    "            #dicom_file = pydicom.read_file(fpath)\n",
    "            #if dicom_file.file_meta.TransferSyntaxUID.name =='JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])' or dicom_file.BitsStored!=16:\n",
    "            #    continue\n",
    "            #if dicom_file.BitsStored!=16:\n",
    "            #    continue\n",
    "            #img = load_dicom(fpath)        \n",
    "\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(klass)\n",
    "            #lab=train_JPEG_BS_.loc[train_JPEG_BS_.StudyInstanceUID == klass,['patient_overall','C1','C2','C3','C4','C5','C6','C7']].values[0].tolist()\n",
    "            #print('lab:',lab)\n",
    "            #labels.append(train_JPEG_BS_.loc[train_JPEG_BS_.StudyInstanceUID == klass,['patient_overall','C1','C2','C3','C4','C5','C6','C7']].values[0].tolist())\n",
    "            \n",
    "            #print('fpath:',fpath)\n",
    "            #print('labels:',labels)\n",
    "    else:\n",
    "        print('class ', klass, ' has only', len(flist), ' samples and will not be included in dataframe')\n",
    "        \n",
    "Fseries=pd.Series(filepaths, name='filepaths')\n",
    "Lseries=pd.Series(labels, name='labels')        \n",
    "df=pd.concat([Fseries, Lseries], axis=1)\n",
    "#display(\"df:\",df)\n",
    "\n",
    "train_df, dummy_df=train_test_split(df, train_size=.9, shuffle=True, random_state=123, stratify=df['labels'])\n",
    "valid_df, test_df=train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=123, stratify=dummy_df['labels'])\n",
    "\n",
    "print('train_df lenght: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n",
    "# get the number of classes and the images count for each class in train_df\n",
    "\n",
    "classes=sorted(list(train_df['labels'].unique()))\n",
    "class_count = len(classes)\n",
    "print('The number of classes in the dataset is: ', class_count)\n",
    "groups=train_df.groupby('labels')\n",
    "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
    "countlist=[]\n",
    "classlist=[]\n",
    "no=0\n",
    "for label in sorted(list(train_df['labels'].unique())):\n",
    "    group=groups.get_group(label)\n",
    "    countlist.append(len(group))\n",
    "    classlist.append(label)\n",
    "    print(no,'{0:^30s} {1:^13s}'.format(label, str(len(group))))\n",
    "    no+=1\n",
    "\n",
    "# get the classes with the minimum and maximum number of train images\n",
    "max_value=np.max(countlist)\n",
    "max_index=countlist.index(max_value)\n",
    "max_class=classlist[max_index]\n",
    "min_value=np.min(countlist)\n",
    "min_index=countlist.index(min_value)\n",
    "min_class=classlist[min_index]\n",
    "print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n",
    "# lets get the average height and width of a sample of the train images\n",
    "ht=0\n",
    "wt=0\n",
    "# select 100 random samples of train_df\n",
    "train_df_sample=train_df.sample(n=200, random_state=123,axis=0)\n",
    "for i in range (len(train_df_sample)):\n",
    "    fpath=train_df_sample['filepaths'].iloc[i]\n",
    "    #print('fpath:',fpath)\n",
    "    img=cv2.imread(fpath)\n",
    "    shape=img.shape\n",
    "    ht += shape[0]\n",
    "    wt += shape[1]\n",
    "print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trim\"></a>\n",
    "# <center>Trim train_df so no class has more than 200 images</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.320745Z",
     "iopub.status.idle": "2022-08-27T15:42:21.321339Z",
     "shell.execute_reply": "2022-08-27T15:42:21.321052Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.321024Z"
    }
   },
   "outputs": [],
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    groups=df.groupby(column)    \n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique(): \n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)    \n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group        \n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    return trimmed_df\n",
    "\n",
    "max_samples=100 # since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
    "min_samples=36\n",
    "column='labels'\n",
    "train_df= trim(train_df, max_samples, min_samples, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"balance\"></a>\n",
    "# <center>Balance train_df by creating augmented images</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.323252Z",
     "iopub.status.idle": "2022-08-27T15:42:21.324035Z",
     "shell.execute_reply": "2022-08-27T15:42:21.323765Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.323737Z"
    }
   },
   "outputs": [],
   "source": [
    "def balance(df, n, working_dir, img_size):\n",
    "    df=df.copy()\n",
    "    print('Initial length of dataframe is ', len(df))\n",
    "    \n",
    "    aug_dir=os.path.join(working_dir, 'aug')# directory to store augmented images\n",
    "    print('aug_dir:',aug_dir)\n",
    "    if os.path.isdir(aug_dir):# start with an empty directory\n",
    "        shutil.rmtree(aug_dir)\n",
    "    os.mkdir(aug_dir)        \n",
    "    for label in df['labels'].unique():    \n",
    "        dir_path=os.path.join(aug_dir,label)    \n",
    "        os.mkdir(dir_path) # make class directories within aug directory\n",
    "    # create and store the augmented images  \n",
    "    total=0\n",
    "    gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n",
    "                                  height_shift_range=.2, zoom_range=.2)\n",
    "    groups=df.groupby('labels') # group by class\n",
    "    print('groups:',groups)\n",
    "    for label in df['labels'].unique():  # for every class               \n",
    "        group=groups.get_group(label)  # a dataframe holding only rows with the specified label \n",
    "        sample_count=len(group)   # determine how many samples there are in this class  \n",
    "        #print('sample_count:',sample_count)\n",
    "        #print('n:',n)\n",
    "        if sample_count< n: # if the class has less than target number of images\n",
    "            aug_img_count=0\n",
    "            delta=n - sample_count  # number of augmented images to create\n",
    "            print('delta:',delta)\n",
    "            target_dir=os.path.join(aug_dir, label)  # define where to write the images\n",
    "            print('target_dir:',target_dir)\n",
    "            msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n",
    "            print(msg, '\\r', end='') # prints over on the same line\n",
    "            aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=img_size,\n",
    "                                            class_mode=None, batch_size=1, shuffle=False, \n",
    "                                            save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n",
    "                                            save_format='png') #'dcm') #'jpg')\n",
    "            while aug_img_count<delta:\n",
    "                images=next(aug_gen)            \n",
    "                aug_img_count += len(images)\n",
    "            total +=aug_img_count\n",
    "    print('Total Augmented images created= ', total)\n",
    "    # create aug_df and merge with train_df to create composite training set ndf\n",
    "    aug_fpaths=[]\n",
    "    aug_labels=[]\n",
    "    classlist=os.listdir(aug_dir)\n",
    "    for klass in classlist:\n",
    "        classpath=os.path.join(aug_dir, klass)     \n",
    "        flist=os.listdir(classpath)    \n",
    "        for f in flist:        \n",
    "            fpath=os.path.join(classpath,f)         \n",
    "            aug_fpaths.append(fpath)\n",
    "            aug_labels.append(klass)\n",
    "    Fseries=pd.Series(aug_fpaths, name='filepaths')\n",
    "    Lseries=pd.Series(aug_labels, name='labels')\n",
    "    aug_df=pd.concat([Fseries, Lseries], axis=1)         \n",
    "    df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n",
    "    print('Length of augmented dataframe is now ', len(df))\n",
    "    return df \n",
    "\n",
    "n=200 # number of samples in each class\n",
    "working_dir=r'./' # directory to store augmented images\n",
    "img_size=(IMG_SIZE,IMG_SIZE)  #(200,200) # size of augmented images\n",
    "train_df=balance(train_df, n, working_dir, img_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generators\"></a>\n",
    "# <center>Create the train_gen, test_gen final_test_gen and valid_gen</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.325685Z",
     "iopub.status.idle": "2022-08-27T15:42:21.326378Z",
     "shell.execute_reply": "2022-08-27T15:42:21.326094Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.326033Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=20 # We will use and EfficientetB3 model, with image size of (200, 250) this size should not cause resource error\n",
    "trgen=ImageDataGenerator(horizontal_flip=True,rotation_range=20, width_shift_range=.2,\n",
    "                                  height_shift_range=.2, zoom_range=.2)\n",
    "t_and_v_gen=ImageDataGenerator()\n",
    "msg='{0:70s} for train generator'.format(' ')\n",
    "print(msg, '\\r', end='') # prints over on the same line\n",
    "\n",
    "train_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                   class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "msg='{0:70s} for valid generator'.format(' ')\n",
    "print(msg, '\\r', end='') # prints over on the same line\n",
    "valid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "# for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n",
    "# this insures that we go through all the sample in the test set exactly once.\n",
    "length=len(test_df)\n",
    "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "test_steps=int(length/test_batch_size)\n",
    "msg='{0:70s} for test generator'.format(' ')\n",
    "print(msg, '\\r', end='') # prints over on the same line\n",
    "\n",
    "test_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "# from the generator we can get information we will need later\n",
    "classes=list(train_gen.class_indices.keys())\n",
    "class_indices=list(train_gen.class_indices.values())\n",
    "class_count=len(classes)\n",
    "labels=test_gen.labels\n",
    "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"show\"></a>\n",
    "# <center>Create a function to show example training images</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.327805Z",
     "iopub.status.idle": "2022-08-27T15:42:21.328383Z",
     "shell.execute_reply": "2022-08-27T15:42:21.328089Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.328064Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_image_samples(gen ):\n",
    "    t_dict=gen.class_indices\n",
    "    classes=list(t_dict.keys())    \n",
    "    images,labels=next(gen) # get a sample batch from the generator \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    length=len(labels)\n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):        \n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        \n",
    "        image=images[i] /255       \n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=14)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "show_image_samples(train_gen )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "# <center>Create a model using transfer learning with EfficientNetB3</center>\n",
    "### NOTE experts advise you make the base model initially not trainable. Then train for some number of epochs\n",
    "### then fine tune model by making base model trainable and run more epochs\n",
    "### I have found this to be WRONG!!!!\n",
    "### Making the base model trainable from the outset leads to faster convegence and a lower validation loss\n",
    "### for the same number of total epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.330981Z",
     "iopub.status.idle": "2022-08-27T15:42:21.331587Z",
     "shell.execute_reply": "2022-08-27T15:42:21.331322Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.331296Z"
    }
   },
   "outputs": [],
   "source": [
    "img_shape=(img_size[0], img_size[1], 3)\n",
    "model_name='EfficientNetB0'\n",
    "base_model=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
    "\n",
    "# Note you are always told NOT to make the base model trainable initially- that is WRONG you get better results leaving it trainable\n",
    "base_model.trainable=True\n",
    "x=base_model.output\n",
    "x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "x=Dropout(rate=.4, seed=123)(x)       \n",
    "output=Dense(class_count, activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "lr=.001 # start with this learning rate\n",
    "model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"callback\"></a>\n",
    "# <center>Create a custom Keras callback to continue and optionally set LR or halt training</center>\n",
    "The LR_ASK callback is a convenient callback that allows you to continue training for ask_epoch more epochs or to halt training.  \n",
    "If you elect to continue training for more epochs you are given the option to retain the current learning rate (LR) or to  \n",
    "enter a new value for the learning rate. The form of use is:  \n",
    "ask=LR_ASK(model,epochs, ask_epoch) where:  \n",
    "* model is a string which is the name of your compiled model\n",
    "* epochs is an integer which is the number of epochs to run specified in model.fit\n",
    "* ask_epoch is an integer. If ask_epoch is set to a value say 5 then the model will train for 5 epochs.  \n",
    "  then the user is ask to enter H to halt training, or enter an inter value. For example if you enter 4  \n",
    "  training will continue for 4 more epochs to epoch 9 then you will be queried again. Once you enter an  \n",
    "  integer value you are prompted to press ENTER to continue training using the current learning rate  \n",
    "  or to enter a new value for the learning rate.  \n",
    "  \n",
    " At the end of training the model weights are set to the weights for the epoch that achieved the lowest validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.334139Z",
     "iopub.status.idle": "2022-08-27T15:42:21.334976Z",
     "shell.execute_reply": "2022-08-27T15:42:21.334679Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.334647Z"
    }
   },
   "outputs": [],
   "source": [
    "class LR_ASK(keras.callbacks.Callback):\n",
    "    def __init__ (self, model, epochs,  ask_epoch): # initialization of the callback\n",
    "        super(LR_ASK, self).__init__()\n",
    "        self.model=model               \n",
    "        self.ask_epoch=ask_epoch\n",
    "        self.epochs=epochs\n",
    "        self.ask=True # if True query the user on a specified epoch\n",
    "        self.lowest_vloss=np.inf\n",
    "        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "        self.best_epoch=1\n",
    "        \n",
    "        \n",
    "    def on_train_begin(self, logs=None): # this runs on the beginning of training\n",
    "        if self.ask_epoch == 0: \n",
    "            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n",
    "            self.ask_epoch=1\n",
    "        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n",
    "            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n",
    "            self.ask=False # do not query the user\n",
    "        if self.epochs == 1:\n",
    "            self.ask=False # running only for 1 epoch so do not query user\n",
    "        else:\n",
    "            print('Training will proceed until epoch', ask_epoch,' then you will be asked to') \n",
    "            print(' enter H to halt training or enter an integer for how many more epochs to run then be asked again')  \n",
    "        self.start_time= time.time() # set the time at which training started\n",
    "        \n",
    "    def on_train_end(self, logs=None):   # runs at the end of training  \n",
    "        print('loading model with weights from epoch ', self.best_epoch)\n",
    "        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n",
    "        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n",
    "        hours = tr_duration // 3600\n",
    "        minutes = (tr_duration - (hours * 3600)) // 60\n",
    "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
    "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
    "        print (msg, flush=True) # print out training duration time\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n",
    "        if v_loss< self.lowest_vloss:\n",
    "            self.lowest_vloss=v_loss\n",
    "            self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n",
    "            self.best_epoch=epoch + 1\n",
    "            print (f'\\n validation loss of {v_loss:7.4f} is below lowest loss, saving weights from epoch {str(epoch + 1):3s} as best weights')\n",
    "        else:\n",
    "            print (f'\\n validation loss of {v_loss:7.4f} is above lowest loss of {self.lowest_vloss:7.4f} keeping weights from epoch {str(self.best_epoch)} as best weights')\n",
    "        \n",
    "        if self.ask: # are the conditions right to query the user?\n",
    "            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n",
    "                print('\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again')\n",
    "                ans=input()\n",
    "                \n",
    "                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n",
    "                    print ('you entered ', ans, ' Training halted on epoch ', epoch+1, ' due to user input\\n', flush=True)\n",
    "                    self.model.stop_training = True # halt training\n",
    "                else: # user wants to continue training\n",
    "                    self.ask_epoch += int(ans)\n",
    "                    if self.ask_epoch > self.epochs:\n",
    "                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n",
    "                    else:\n",
    "                        print ('you entered ', ans, ' Training will continue to epoch ', self.ask_epoch, flush=True)\n",
    "                        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "                        print(f'current LR is  {lr:7.5f}  hit enter to keep  this LR or enter a new LR')\n",
    "                        ans=input(' ')\n",
    "                        if ans =='':\n",
    "                            print (f'keeping current LR of {lr:7.5f}')\n",
    "                        else:\n",
    "                            new_lr=float(ans)\n",
    "                            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "                            print(' changing LR to ', ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"callbacks\"></a>\n",
    "# <center>Instantiate custom callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.336170Z",
     "iopub.status.idle": "2022-08-27T15:42:21.336723Z",
     "shell.execute_reply": "2022-08-27T15:42:21.336460Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.336434Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs=50  #200\n",
    "ask_epoch=60  #100\n",
    "ask=LR_ASK(model, epochs,  ask_epoch)\n",
    "#rlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\n",
    "#callbacks=[rlronp, ask]\n",
    "callbacks=[ask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "# <center>Train the model\n",
    "### Note unlike how you are told it is BETTER to make the base model trainable from the outset\n",
    "### It will converge faster and have a lower validation losss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.338333Z",
     "iopub.status.idle": "2022-08-27T15:42:21.338884Z",
     "shell.execute_reply": "2022-08-27T15:42:21.338635Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.338609Z"
    }
   },
   "outputs": [],
   "source": [
    "history=model.fit(x=train_gen,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=valid_gen,\n",
    "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plot\"></a>\n",
    "# <center>Define a function to plot the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.340354Z",
     "iopub.status.idle": "2022-08-27T15:42:21.340892Z",
     "shell.execute_reply": "2022-08-27T15:42:21.340645Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.340619Z"
    }
   },
   "outputs": [],
   "source": [
    "def tr_plot(tr_data, start_epoch):\n",
    "    #Plot the training and validation data\n",
    "    tacc=tr_data.history['accuracy']\n",
    "    tloss=tr_data.history['loss']\n",
    "    vacc=tr_data.history['val_accuracy']\n",
    "    vloss=tr_data.history['val_loss']\n",
    "    Epoch_count=len(tacc)+ start_epoch\n",
    "    Epochs=[]\n",
    "    for i in range (start_epoch ,Epoch_count):\n",
    "        Epochs.append(i+1)   \n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    acc_highest=vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(24,8))\n",
    "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
    "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout    \n",
    "    plt.show()\n",
    "    \n",
    "tr_plot(history,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"result\"></a>\n",
    "# <center>Make Predictions on the test set</a>\n",
    "### Define a function which takes in a test generator and an integer test_steps\n",
    "### and generates predictions on the test set including a confusion matric\n",
    "### and a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.342824Z",
     "iopub.status.idle": "2022-08-27T15:42:21.343379Z",
     "shell.execute_reply": "2022-08-27T15:42:21.343108Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.343083Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictor(test_gen, test_steps):\n",
    "    y_pred= []\n",
    "    y_true=test_gen.labels\n",
    "    classes=list(test_gen.class_indices.keys())\n",
    "    class_count=len(classes)\n",
    "    errors=0\n",
    "    preds=model.predict(test_gen, verbose=1)\n",
    "    tests=len(preds)    \n",
    "    for i, p in enumerate(preds):        \n",
    "        pred_index=np.argmax(p)         \n",
    "        true_index=test_gen.labels[i]  # labels are integer values        \n",
    "        if pred_index != true_index: # a misclassification has occurred                                           \n",
    "            errors=errors + 1\n",
    "        y_pred.append(pred_index)\n",
    "            \n",
    "    acc=( 1-errors/tests) * 100 \n",
    "    print(f'there were {errors} errors in {tests} tests for an accuracy of {acc:6.2f}')\n",
    "    ypred=np.array(y_pred)\n",
    "    ytrue=np.array(y_true)\n",
    "    if class_count <=30:\n",
    "        cm = confusion_matrix(ytrue, ypred )\n",
    "        # plot the confusion matrix\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "        plt.xticks(np.arange(class_count)+.5, classes, rotation=0)\n",
    "        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create classification report\n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
    "    return errors, tests\n",
    "errors, tests=predictor(test_gen, test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.344864Z",
     "iopub.status.idle": "2022-08-27T15:42:21.345454Z",
     "shell.execute_reply": "2022-08-27T15:42:21.345230Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.345134Z"
    }
   },
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "# <center>Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.346457Z",
     "iopub.status.idle": "2022-08-27T15:42:21.346837Z",
     "shell.execute_reply": "2022-08-27T15:42:21.346673Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.346656Z"
    }
   },
   "outputs": [],
   "source": [
    "subject='plant disease' \n",
    "acc=str(( 1-errors/tests) * 100)\n",
    "index=acc.rfind('.')\n",
    "acc=acc[:index + 3]\n",
    "save_id= subject + '_' + str(acc) + '.h5' \n",
    "model_save_loc=os.path.join('working_dir', save_id)\n",
    "model.save(model_save_loc)\n",
    "print ('model was saved as ' , model_save_loc ) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.348799Z",
     "iopub.status.idle": "2022-08-27T15:42:21.349325Z",
     "shell.execute_reply": "2022-08-27T15:42:21.349045Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.349025Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#LOAD MODEL\n",
    "#from tensorflow.keras import layers, Sequential\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\"\"\"\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "MODEL_PATH = './M-EfficientNetB3_e100.h5'\n",
    "\n",
    "model = load_model(MODEL_PATH,compile=False) #, custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data test to png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.351855Z",
     "iopub.status.idle": "2022-08-27T15:42:21.352305Z",
     "shell.execute_reply": "2022-08-27T15:42:21.352087Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.352067Z"
    }
   },
   "outputs": [],
   "source": [
    "test_csv_=test_csv[0:].copy()\n",
    "txt_JPEG='JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])'\n",
    "Impli='Implicit VR Little Endian'\n",
    "Expli='Explicit VR Little Endian'\n",
    "\n",
    "for pan in range (len(test_csv_)):\n",
    "    w=test_csv_.loc[pan]['StudyInstanceUID']\n",
    "    pat = DIR+'train_images/'+w \n",
    "    z=os.listdir(pat)[0]\n",
    "    dicom_file = pydicom.read_file(pat+'/'+z)\n",
    "    #print(pan,dicom_file.file_meta.TransferSyntaxUID.name , dicom_file.BitsStored)\n",
    "    \n",
    "    if dicom_file.file_meta.TransferSyntaxUID.name == Impli:\n",
    "        test_csv_.loc[pan,'Impli']=1\n",
    "    else:\n",
    "        test_csv_.loc[pan,'Impli']=0\n",
    "        \n",
    "    if dicom_file.file_meta.TransferSyntaxUID.name == Expli:\n",
    "        test_csv_.loc[pan,'Expli']=1\n",
    "    else:\n",
    "        estn_csv_.loc[pan,'Expli']=0\n",
    "    \n",
    "    if dicom_file.file_meta.TransferSyntaxUID.name == txt_JPEG:\n",
    "        test_csv_.loc[pan,'txt_JPEG']=1\n",
    "    else:\n",
    "        test_csv_.loc[pan,'txt_JPEG']=0\n",
    "        \n",
    "    if dicom_file.BitsStored == 16:\n",
    "        test_csv_.loc[pan,'BS_16']=1\n",
    "    else:\n",
    "        test_csv_.loc[pan,'BS_16']=0\n",
    "        \n",
    "    test_csv_.loc[pan,'Jum_dcm']=len(os.listdir(pat))\n",
    "test_csv_\n",
    "\n",
    "test_JPEG_BS =train_csv_.loc[test_csv_.txt_JPEG==0].loc[test_csv_.BS_16==1].loc[test_csv_.patient_overall==1]\n",
    "display(test_JPEG_BS)\n",
    "print('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t     ','\\033[91m'+'Total data dcm :  ' +str(test_JPEG_BS.Jum_dcm.sum()) + '\\033[0m')\n",
    "\n",
    "#=======================\n",
    "\n",
    "test_JPEG_BS_=test_JPEG_BS.copy()\n",
    "#lim1=220\n",
    "#lim2=250\n",
    "#test_JPEG_BS_=test_JPEG_BS_.loc[test_JPEG_BS_.Jum_dcm>lim1].loc[test_JPEG_BS_.Jum_dcm<lim2]\n",
    "#print('min:',test_JPEG_BS_.Jum_dcm.min(), 'max:',test_JPEG_BS_.Jum_dcm.max(), 'sum:',test_JPEG_BS_.Jum_dcm.sum())\n",
    "\n",
    "test_JPEG_BS_=test_JPEG_BS_.sort_values(by=['StudyInstanceUID'],ignore_index=True)\n",
    "\n",
    "display(test_JPEG_BS_.head())\n",
    "img_count=test_JPEG_BS_.Jum_dcm.sum()\n",
    "print('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t     ','\\033[91m'+'Total data dcm :  ' +str(img_count) + '\\033[0m')\n",
    "print('')\n",
    "print('img_count:',img_count)\n",
    "print('Cgab.nunique:',test_JPEG_BS_.Cgab.nunique())\n",
    "#print('Cgab.nunique:',train_JPEG_BS_.C1.nunique())\n",
    "print('')\n",
    "print('C1=1:',test_JPEG_BS_.loc[test_JPEG_BS_.C1==1]['C1'].count(),'dari',test_JPEG_BS_.C1.count())\n",
    "print('C1=0:',test_JPEG_BS_.loc[test_JPEG_BS_.C1==0]['C1'].count(),'dari',test_JPEG_BS_.C1.count())\n",
    "\n",
    "#=========================\n",
    "\n",
    "#covert dcm to jpg/png\n",
    "import cv2\n",
    "from PIL import Image\n",
    "IMG_SIZE=200\n",
    "\n",
    "# Specify the .dcm folder path\n",
    "folder_path = test_JPEG_BS_.StudyInstanceUID.values.tolist()  #[0:2]\n",
    "f_dest='test_images'  #+str(lim1)+'_'+str(lim2)\n",
    "\n",
    "try: \n",
    "    os.mkdir(f_dest)\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "\n",
    "i=0 \n",
    "for n, image in enumerate(folder_path[0:]):  #2018   \n",
    "    fold=train_JPEG_BS_.loc[test_JPEG_BS_.StudyInstanceUID==str(image)].C1.values[0]\n",
    "    \n",
    "    try: \n",
    "        os.mkdir(f_dest+'/'+str(fold))\n",
    "    except OSError as error: \n",
    "        print(error)  \n",
    "        \n",
    "    for img in os.listdir(test_images_dir+image)[0:]:       \n",
    "        ds = pydicom.read_file(test_images_dir+image+'/'+img)        \n",
    "        pixel_array_numpy = ds.pixel_array\n",
    "        pixel_array_numpy = cv.resize(pixel_array_numpy, (IMG_SIZE, IMG_SIZE))\n",
    "        img_mem = Image.fromarray(pixel_array_numpy)               \n",
    "        img_mem.save(f_dest+'/'+str(fold)+'/'+str(image)+'.'+str(img).replace(\".dcm\",\".png\"))\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print('{} image converted to png'.format(i))\n",
    "            print('   f_dest:',f_dest+'/'+str(fold)+'/'+str(image)+'.'+str(img).replace(\".dcm\",\".png\"))\n",
    "        i+=1\n",
    "        #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.354117Z",
     "iopub.status.idle": "2022-08-27T15:42:21.354521Z",
     "shell.execute_reply": "2022-08-27T15:42:21.354358Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.354340Z"
    }
   },
   "outputs": [],
   "source": [
    "classlist[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.355460Z",
     "iopub.status.idle": "2022-08-27T15:42:21.355851Z",
     "shell.execute_reply": "2022-08-27T15:42:21.355675Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.355656Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_train_lab=['blast','brown','healthy']\n",
    "data_train_lab=classlist\n",
    "\n",
    "data_train_nom=[]\n",
    "for k in range (0,int(len(data_train_lab))):\n",
    "    data_train_nom.append(k)\n",
    "data_train_nom\n",
    "\n",
    "print(data_train_lab)\n",
    "print(data_train_nom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.357646Z",
     "iopub.status.idle": "2022-08-27T15:42:21.358104Z",
     "shell.execute_reply": "2022-08-27T15:42:21.357889Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.357870Z"
    }
   },
   "outputs": [],
   "source": [
    "# MEMILIH DATA UNTUK TEST\n",
    "#data_test=data_dir\n",
    "\n",
    "def load_image(image_file):\n",
    "    img = Image.open(image_file)\n",
    "    return img \n",
    "\n",
    "def prediksi(im):\n",
    "    #input_size = (224,224)\n",
    "    input_size = (200,200)\n",
    "    channel = (3,)\n",
    "    input_shape = input_size + channel\n",
    "    labels1 = data_train_lab\n",
    "    labels2 = data_train_nom\n",
    "\n",
    "    def preprocess(img,input_size):\n",
    "        nimg = img.convert('RGB').resize(input_size, resample= 0)\n",
    "        img_arr = (np.array(nimg))/255\n",
    "        return img_arr\n",
    "\n",
    "    def reshape(imgs_arr):\n",
    "        return np.stack(imgs_arr, axis=0)\n",
    "\n",
    "    #from tensorflow.keras.models import load_model\n",
    "    #MODEL_PATH = 'model-Zin_1.h5'\n",
    "    #MODEL_PATH = save_model_path\n",
    "    #model = load_model(MODEL_PATH,compile=False, custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "    \n",
    "    # read image\n",
    "    #im = Image.open(data_uji)\n",
    "    X = preprocess(im,input_size)\n",
    "    X = reshape([X])\n",
    "    y = model.predict(X)\n",
    "    \n",
    "    HasilPrediksi1=labels1[np.argmax(y)],  \n",
    "    HasilPrediksi2=labels2[np.argmax(y)],\n",
    "    #print()\n",
    "    #print('Keterangan = ',labels)\n",
    "    #print()\n",
    "    #st.write( 'HasilPrediksi = ', HasilPrediksi)\n",
    "    return HasilPrediksi1,HasilPrediksi2,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.360632Z",
     "iopub.status.idle": "2022-08-27T15:42:21.361092Z",
     "shell.execute_reply": "2022-08-27T15:42:21.360908Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.360887Z"
    }
   },
   "outputs": [],
   "source": [
    "sdir=r'../input/plant-disease-expert/Image Data base/'\n",
    "len(os.listdir(sdir+'Image Data base/'))\n",
    "os.listdir(sdir+'Image Data base/')\n",
    "len(os.listdir(sdir+'Image Data base/'))\n",
    "os.listdir(sdir+'Image Data base/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.363030Z",
     "iopub.status.idle": "2022-08-27T15:42:21.363465Z",
     "shell.execute_reply": "2022-08-27T15:42:21.363286Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.363267Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from PIL import Image\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "#dImages = '/content/drive/MyDrive/Colab Notebooks/Microsoft Rice Disease Classification Challenge/Data/Images/'\n",
    "#dImages = 'Data-score-99/TrainImages_no_rgn/'  #maindir2 #'input/ricediseases2/'\n",
    "dImages = sdir  #+'/Image Data base/'\n",
    "\n",
    "gamb=os.listdir(dImages)[0] #[0]\n",
    "image_file = dImages+'/'+gamb\n",
    "print(gamb)\n",
    "if image_file is not None:\n",
    "    print(image_file+'/'+os.listdir(image_file)[0])\n",
    "    img_uji = load_image(image_file+'/'+os.listdir(image_file)[0])  \n",
    "    HasilPrediksi1,HasilPrediksi2,y = prediksi(img_uji)\n",
    "    print('y=',y)\n",
    "    #print('y0=',y[0][0])\n",
    "    #print('y1=',y[0][1])\n",
    "    \n",
    "    print(\"HASIL PREDIKSI = \",HasilPrediksi2[0],' (',HasilPrediksi1[0],')')\n",
    "\n",
    "    img = cv2.imread(image_file+'/'+os.listdir(image_file)[0])\n",
    "    height, width, channels = img.shape\n",
    "    print(height, width, channels)\n",
    "    img=cv2.resize(img, (200,200), interpolation = cv2.INTER_AREA)\n",
    "    #cv2_imshow(img)\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.365078Z",
     "iopub.status.idle": "2022-08-27T15:42:21.365499Z",
     "shell.execute_reply": "2022-08-27T15:42:21.365329Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.365311Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "g=0\n",
    "#maindir0='Data-score-99/TestImages_no_rgn/'\n",
    "maindir0=image_file\n",
    "SampleSubmission=pd.read_csv('Data-score-99/SampleSubmission.csv')\n",
    "\n",
    "SamSub=SampleSubmission.copy()\n",
    "SamSub=SamSub.set_index('Image_id')\n",
    "\n",
    "#for jpg in SampleSubmission['Image_id'][0:]: \n",
    "for jpg in image_file+'/'+os.listdir(image_file)#[0]\n",
    "  #print(dImages+jpg)\n",
    "  image_file = maindir0\n",
    "\n",
    "  print(g,' ',jpg)\n",
    "  if image_file is not None:\n",
    "      print(maindir0+jpg)  \n",
    "      img_uji = load_image(maindir0+jpg)  \n",
    "      HasilPrediksi1,HasilPrediksi2,y = prediksi(img_uji)\n",
    "      print(g,jpg,y,HasilPrediksi1,HasilPrediksi2)\n",
    "\n",
    "      SamSub.loc[SamSub.index==jpg,['blast','brown','healthy']]=y    \n",
    "      g+=1\n",
    "\n",
    "\n",
    "display(SamSub)\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path('Data-score-99/'+str(model_name)+'_e'+str(epochs)+'/Sub_'+str(model_name)+'_e'+str(epochs)+'_no_rgn.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "SamSub.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.367535Z",
     "iopub.status.idle": "2022-08-27T15:42:21.367964Z",
     "shell.execute_reply": "2022-08-27T15:42:21.367755Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.367737Z"
    }
   },
   "outputs": [],
   "source": [
    "SampleSubmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-27T15:42:21.369904Z",
     "iopub.status.idle": "2022-08-27T15:42:21.370430Z",
     "shell.execute_reply": "2022-08-27T15:42:21.370197Z",
     "shell.execute_reply.started": "2022-08-27T15:42:21.370129Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('Data-score-99/'+str(model_name)+'_e'+str(epochs)+'/Sub_'+str(model_name)+'_e'+str(epochs)+'_no_rgn.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "SamSub.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
